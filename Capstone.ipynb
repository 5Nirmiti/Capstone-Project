{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0b75c5-cdfa-4e0f-84a0-d90fa1ec5ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Case Study 1: Generative Text for Customer Support Automation\n",
    "#Project Overview: Develop an AI-powered system to automate customer support interactions using generative models like GPT-3.5.\n",
    "#Use Case:\n",
    "#Automated Response Generation:\n",
    "#Problem Statement: Customer support teams are overwhelmed by repetitive inquiries that could be handled by automated systems.\n",
    "#Solution: Implement a generative AI model to automatically generate accurate and context-aware responses to common customer queries, reducing the load on human agents and improving response times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8080c634-c320-4c02-83c8-d8006e107f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.42.4-py3-none-any.whl.metadata (43 kB)\n",
      "     ---------------------------------------- 0.0/43.6 kB ? eta -:--:--\n",
      "     --------- ------------------------------ 10.2/43.6 kB ? eta -:--:--\n",
      "     ----------------- -------------------- 20.5/43.6 kB 162.5 kB/s eta 0:00:01\n",
      "     ----------------------------------- -- 41.0/43.6 kB 245.8 kB/s eta 0:00:01\n",
      "     -------------------------------------- 43.6/43.6 kB 212.7 kB/s eta 0:00:00\n",
      "Requirement already satisfied: filelock in c:\\users\\nirmiti\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Collecting huggingface-hub<1.0,>=0.23.2 (from transformers)\n",
      "  Downloading huggingface_hub-0.23.4-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17 in c:\\users\\nirmiti\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\nirmiti\\anaconda3\\lib\\site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\nirmiti\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\nirmiti\\anaconda3\\lib\\site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in c:\\users\\nirmiti\\anaconda3\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.3-cp311-none-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers)\n",
      "  Downloading tokenizers-0.19.1-cp311-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\nirmiti\\anaconda3\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\nirmiti\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\nirmiti\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.9.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\nirmiti\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nirmiti\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nirmiti\\anaconda3\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nirmiti\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nirmiti\\anaconda3\\lib\\site-packages (from requests->transformers) (2024.2.2)\n",
      "Downloading transformers-4.42.4-py3-none-any.whl (9.3 MB)\n",
      "   ---------------------------------------- 0.0/9.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/9.3 MB 1.3 MB/s eta 0:00:08\n",
      "   ---------------------------------------- 0.0/9.3 MB 487.6 kB/s eta 0:00:20\n",
      "   ---------------------------------------- 0.1/9.3 MB 744.7 kB/s eta 0:00:13\n",
      "   ---------------------------------------- 0.1/9.3 MB 726.2 kB/s eta 0:00:13\n",
      "    --------------------------------------- 0.2/9.3 MB 980.4 kB/s eta 0:00:10\n",
      "    --------------------------------------- 0.2/9.3 MB 1.1 MB/s eta 0:00:09\n",
      "   - -------------------------------------- 0.3/9.3 MB 1.1 MB/s eta 0:00:09\n",
      "   - -------------------------------------- 0.3/9.3 MB 1.1 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 0.5/9.3 MB 1.2 MB/s eta 0:00:08\n",
      "   -- ------------------------------------- 0.6/9.3 MB 1.4 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 0.7/9.3 MB 1.4 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 0.8/9.3 MB 1.6 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 0.9/9.3 MB 1.6 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 1.0/9.3 MB 1.7 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 1.1/9.3 MB 1.7 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 1.2/9.3 MB 1.7 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 1.3/9.3 MB 1.8 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 1.5/9.3 MB 1.9 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 1.5/9.3 MB 1.9 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 1.6/9.3 MB 1.9 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 1.7/9.3 MB 1.9 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 1.8/9.3 MB 1.9 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 1.9/9.3 MB 2.0 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 2.1/9.3 MB 2.0 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 2.3/9.3 MB 2.1 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 2.3/9.3 MB 2.0 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 2.5/9.3 MB 2.1 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 2.6/9.3 MB 2.2 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 2.8/9.3 MB 2.2 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 2.9/9.3 MB 2.2 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 3.1/9.3 MB 2.3 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 3.2/9.3 MB 2.3 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 3.5/9.3 MB 2.4 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 3.6/9.3 MB 2.4 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 3.7/9.3 MB 2.4 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 3.9/9.3 MB 2.5 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 4.0/9.3 MB 2.5 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 4.2/9.3 MB 2.5 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 4.3/9.3 MB 2.5 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 4.4/9.3 MB 2.6 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 4.6/9.3 MB 2.5 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 4.7/9.3 MB 2.6 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 4.7/9.3 MB 2.5 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 4.9/9.3 MB 2.5 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 5.0/9.3 MB 2.6 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 5.3/9.3 MB 2.6 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 5.4/9.3 MB 2.6 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 5.7/9.3 MB 2.7 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 5.9/9.3 MB 2.7 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 6.2/9.3 MB 2.8 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 6.4/9.3 MB 2.8 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 6.4/9.3 MB 2.7 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 6.9/9.3 MB 2.9 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 7.0/9.3 MB 2.9 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 7.4/9.3 MB 3.0 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 7.6/9.3 MB 3.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 7.9/9.3 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 8.0/9.3 MB 3.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 8.2/9.3 MB 3.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 8.6/9.3 MB 3.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 8.8/9.3 MB 3.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 8.9/9.3 MB 3.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.0/9.3 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.1/9.3 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.3/9.3 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.3/9.3 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.3/9.3 MB 3.1 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.23.4-py3-none-any.whl (402 kB)\n",
      "   ---------------------------------------- 0.0/402.6 kB ? eta -:--:--\n",
      "   -------------------------- ------------- 266.2/402.6 kB 8.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  399.4/402.6 kB 6.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 402.6/402.6 kB 4.2 MB/s eta 0:00:00\n",
      "Downloading safetensors-0.4.3-cp311-none-win_amd64.whl (287 kB)\n",
      "   ---------------------------------------- 0.0/287.3 kB ? eta -:--:--\n",
      "   --------------------------- ----------- 204.8/287.3 kB 12.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  286.7/287.3 kB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 287.3/287.3 kB 2.9 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.19.1-cp311-none-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.2/2.2 MB 6.1 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 0.4/2.2 MB 5.4 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 0.5/2.2 MB 4.7 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 0.7/2.2 MB 4.3 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 0.9/2.2 MB 4.2 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 1.0/2.2 MB 3.8 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 1.1/2.2 MB 3.4 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 1.1/2.2 MB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.2/2.2 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.3/2.2 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.3/2.2 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.3/2.2 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.3/2.2 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.3/2.2 MB 2.8 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.6/2.2 MB 2.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 2.1/2.2 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 2.8 MB/s eta 0:00:00\n",
      "Installing collected packages: safetensors, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed huggingface-hub-0.23.4 safetensors-0.4.3 tokenizers-0.19.1 transformers-4.42.4\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1091043-c324-4e4f-bb9a-cb21901ba2e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3666, 598, 318, 21899]\n",
      "[23433, 6865, 301, 9221, 262, 598, 290, 4155, 534, 3335, 338, 3788, 318, 510, 284, 3128, 13]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "import torch\n",
    "\n",
    "file_path = r'C:\\Users\\Nirmiti\\customer_support_data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Loading pre-trained tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "\n",
    "# Tokenize and encoding text data\n",
    "queries = data['query'].tolist()\n",
    "responses = data['response'].tolist()\n",
    "\n",
    "# Tokenize and encoding queries and responses\n",
    "encoded_queries = [tokenizer.encode(query, add_special_tokens=True) for query in queries]\n",
    "encoded_responses = [tokenizer.encode(response, add_special_tokens=True) for response in responses]\n",
    "\n",
    "# Displaying the first encoded query and response\n",
    "print(encoded_queries[0])\n",
    "print(encoded_responses[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d62552ad-8ca6-49bf-a19c-5e58d1e69cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[ 2437,   466,   314,  ..., 50256, 50256, 50256],\n",
      "        [   40,  4398,   470,  ..., 50256, 50256, 50256],\n",
      "        [ 6090,   314, 12233,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 3666,  1502,   318,  ..., 50256, 50256, 50256],\n",
      "        [ 3666,   598,   318,  ..., 50256, 50256, 50256],\n",
      "        [ 6090,   314, 12233,  ..., 50256, 50256, 50256]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([[ 2437,   466,   314,  ..., 50256, 50256, 50256],\n",
      "        [   40,  4398,   470,  ..., 50256, 50256, 50256],\n",
      "        [ 6090,   314, 12233,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 3666,  1502,   318,  ..., 50256, 50256, 50256],\n",
      "        [ 3666,   598,   318,  ..., 50256, 50256, 50256],\n",
      "        [ 6090,   314, 12233,  ..., 50256, 50256, 50256]])}\n"
     ]
    }
   ],
   "source": [
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CustomerSupportDataset(Dataset):\n",
    "    def __init__(self, queries, responses, tokenizer, max_length=512):\n",
    "        self.queries = queries\n",
    "        self.responses = responses\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.queries)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        query = self.queries[idx]\n",
    "        response = self.responses[idx]\n",
    "        \n",
    "        # Encoding the query and response together with a separator token\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            query,\n",
    "            response,\n",
    "            max_length=self.max_length,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            return_tensors='pt',\n",
    "            return_attention_mask=True\n",
    "        )\n",
    "\n",
    "        input_ids = encoding['input_ids'].flatten()\n",
    "        attention_mask = encoding['attention_mask'].flatten()\n",
    "\n",
    "        return {\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask,\n",
    "            'labels': input_ids\n",
    "        }\n",
    "\n",
    "# Creating the dataset and dataloader\n",
    "dataset = CustomerSupportDataset(encoded_queries, encoded_responses, tokenizer)\n",
    "dataloader = DataLoader(dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "# Displaying a batch of data\n",
    "for batch in dataloader:\n",
    "    print(batch)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdb8f15-2cee-4222-93e1-9700f2714232",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nirmiti\\anaconda3\\Lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, AdamW, get_linear_schedule_with_warmup\n",
    "import re\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Loading the pre-trained GPT-2 model\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "\n",
    "# Moving the model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Defining the optimizer and learning rate scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "total_steps = len(dataloader) * 3  # 3 epochs\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps=0, \n",
    "                                            num_training_steps=total_steps)\n",
    "\n",
    "# Defining the training loop\n",
    "def train(model, dataloader, optimizer, scheduler, device, epochs=3):\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for batch in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            print(f'Epoch: {epoch + 1}, Loss: {loss.item()}')\n",
    "\n",
    "# Training the model\n",
    "train(model, dataloader, optimizer, scheduler, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a1e67a-180e-44b1-bd14-52d42ba2d19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "# Evaluating the model\n",
    "validation_loss = evaluate(model, dataloader, device)\n",
    "print(f'Validation Loss: {validation_loss}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61849aa8-2f72-4ae6-9908-623536119ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('C:\\Users\\Nirmiti\\save\\model')\n",
    "tokenizer.save_pretrained('C:\\Users\\Nirmiti\\save\\tokenizer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e7a430-fad7-4834-b093-d07af8ab5004",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "# Loading the saved model and tokenizer\n",
    "model = GPT2LMHeadModel.from_pretrained('C:\\Users\\Nirmiti\\save\\model')\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('C:\\Users\\Nirmiti\\save\\tokenizer')\n",
    "\n",
    "# Function to generate response\n",
    "def generate_response(query):\n",
    "    inputs = tokenizer.encode(query, return_tensors='pt')\n",
    "    outputs = model.generate(inputs, max_length=150, num_return_sequences=1)\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return response\n",
    "\n",
    "# Example usage\n",
    "query = \"How do I reset my password?\"\n",
    "response = generate_response(query)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
